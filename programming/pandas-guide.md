# Python Pandas æµ‹è¯•å·¥ç¨‹å¸ˆç²¾é€šæŒ‡å—

> æ ‡ç­¾: #python #pandas #data-analysis #testing #é¢è¯•
> åˆ›å»ºæ—¶é—´: 2026-02-26
> æ¥æº: [Pandaså®˜æ–¹æ–‡æ¡£](https://pandas.pydata.org/) | [Pandas Tutorial](https://pandas.pydata.org/docs/user_guide/index.html)

## æ¦‚è¿°

Pandas æ˜¯ Python æ•°æ®åˆ†ææ ¸å¿ƒåº“ï¼Œæµ‹è¯•å·¥ç¨‹å¸ˆå¸¸ç”¨å®ƒå¤„ç†æµ‹è¯•æ•°æ®ã€æ•°æ®æ¯”å¯¹ã€ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šç­‰åœºæ™¯ã€‚æœ¬æ–‡æ•´ç†æµ‹è¯•é¢è¯•é«˜é¢‘ Pandas çŸ¥è¯†ç‚¹ï¼ŒæŒ‰é‡è¦ç¨‹åº¦åˆ†ç±»ã€‚

---

## ä¸€ã€çŸ¥è¯†ä½“ç³»æ€»è§ˆ

### æŒæ¡ç¨‹åº¦åˆ†ç±»

| çº§åˆ« | è¯´æ˜ | é¢è¯•æƒé‡ |
|------|------|----------|
| ğŸ”´ å¿…é¡»æŒæ¡ | é¢è¯•å¿…é—®ï¼Œæ—¥å¸¸å¿…ç”¨ | 40% |
| ğŸŸ  é‡è¦ | å¸¸è§è€ƒç‚¹ï¼Œéœ€è¦ç†Ÿç»ƒ | 30% |
| ğŸŸ¡ å¸¸ç”¨ | å·¥ä½œä¸­é¢‘ç¹ä½¿ç”¨ | 20% |
| ğŸŸ¢ äº†è§£ | é«˜çº§åœºæ™¯ï¼ŒçŸ¥é“å³å¯ | 10% |

---

## äºŒã€æ ¸å¿ƒçŸ¥è¯†ç‚¹

### ğŸ”´ å¿…é¡»æŒæ¡

#### 1. æ•°æ®ç»“æ„

```python
import pandas as pd
import numpy as np

# ========== Series ä¸€ç»´æ•°æ® ==========
s = pd.Series([1, 2, 3, 4, 5])
s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])
s = pd.Series({'a': 1, 'b': 2, 'c': 3})

# å¸¸ç”¨å±æ€§
s.values          # å€¼æ•°ç»„
s.index           # ç´¢å¼•
s.dtype           # æ•°æ®ç±»å‹
s.shape           # å½¢çŠ¶

# ========== DataFrame äºŒç»´è¡¨æ ¼ ==========
# ä»å­—å…¸åˆ›å»º
df = pd.DataFrame({
    'name': ['å¼ ä¸‰', 'æå››', 'ç‹äº”'],
    'age': [25, 30, 35],
    'city': ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·']
})

# ä»åˆ—è¡¨åˆ›å»º
df = pd.DataFrame([
    ['å¼ ä¸‰', 25, 'åŒ—äº¬'],
    ['æå››', 30, 'ä¸Šæµ·']
], columns=['name', 'age', 'city'])

# ä» NumPy åˆ›å»º
df = pd.DataFrame(np.random.randn(3, 4), columns=['A', 'B', 'C', 'D'])

# å¸¸ç”¨å±æ€§
df.shape          # (è¡Œæ•°, åˆ—æ•°)
df.columns        # åˆ—å
df.index          # è¡Œç´¢å¼•
df.dtypes         # å„åˆ—æ•°æ®ç±»å‹
df.values         # NumPy æ•°ç»„
df.info()         # åŸºæœ¬ä¿¡æ¯
df.describe()     # ç»Ÿè®¡æè¿°
```

#### 2. æ•°æ®è¯»å–ä¸å†™å…¥

```python
# ========== è¯»å–æ–‡ä»¶ ==========
# CSV
df = pd.read_csv('data.csv')
df = pd.read_csv('data.csv', encoding='utf-8')
df = pd.read_csv('data.csv', sep='\t')           # TSV
df = pd.read_csv('data.csv', header=None)        # æ— è¡¨å¤´
df = pd.read_csv('data.csv', usecols=['col1', 'col2'])  # æŒ‡å®šåˆ—
df = pd.read_csv('data.csv', nrows=1000)         # åªè¯»å‰ N è¡Œ

# Excel
df = pd.read_excel('data.xlsx')
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')
df = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])  # å¤š sheet

# JSON
df = pd.read_json('data.json')
df = pd.read_json('data.json', orient='records')

# SQL
import sqlite3
conn = sqlite3.connect('database.db')
df = pd.read_sql('SELECT * FROM users', conn)
df = pd.read_sql_table('users', conn)

# ========== å†™å…¥æ–‡ä»¶ ==========
df.to_csv('output.csv', index=False)
df.to_csv('output.csv', encoding='utf-8-sig')    # Excel å‹å¥½
df.to_excel('output.xlsx', index=False)
df.to_excel('output.xlsx', sheet_name='Sheet1')
df.to_json('output.json', orient='records', force_ascii=False)

# å¤š sheet
with pd.ExcelWriter('output.xlsx') as writer:
    df1.to_excel(writer, sheet_name='Sheet1')
    df2.to_excel(writer, sheet_name='Sheet2')
```

#### 3. æ•°æ®é€‰æ‹©ä¸è¿‡æ»¤

```python
# ========== é€‰æ‹©åˆ— ==========
df['name']                    # å•åˆ—ï¼ˆSeriesï¼‰
df[['name', 'age']]           # å¤šåˆ—ï¼ˆDataFrameï¼‰
df.name                       # å±æ€§æ–¹å¼ï¼ˆä¸æ¨èï¼‰

# ========== é€‰æ‹©è¡Œ ==========
# ä½ç½®ç´¢å¼•
df.iloc[0]                    # ç¬¬ 1 è¡Œ
df.iloc[0:5]                  # å‰ 5 è¡Œ
df.iloc[[0, 2, 4]]            # æŒ‡å®šè¡Œ

# æ ‡ç­¾ç´¢å¼•
df.loc[0]                     # ç´¢å¼•ä¸º 0 çš„è¡Œ
df.loc[0:5]                   # ç´¢å¼• 0-5 çš„è¡Œ
df.loc[0, 'name']             # æŒ‡å®šå•å…ƒæ ¼

# æ··åˆ
df.iloc[0:5, 0:2]             # å‰ 5 è¡Œï¼Œå‰ 2 åˆ—
df.loc[0:5, ['name', 'age']]

# ========== æ¡ä»¶è¿‡æ»¤ ==========
# å•æ¡ä»¶
df[df['age'] > 25]
df[df['city'] == 'åŒ—äº¬']

# å¤šæ¡ä»¶
df[(df['age'] > 25) & (df['city'] == 'åŒ—äº¬')]
df[(df['age'] > 25) | (df['city'] == 'ä¸Šæµ·')]

# isin
df[df['city'].isin(['åŒ—äº¬', 'ä¸Šæµ·'])]

# åŒ…å«å­—ç¬¦ä¸²
df[df['name'].str.contains('å¼ ')]

# éç©º
df[df['email'].notna()]
df[df['email'].isna()]

# query æ–¹æ³•
df.query('age > 25 and city == "åŒ—äº¬"')
df.query('city in ["åŒ—äº¬", "ä¸Šæµ·"]')
```

#### 4. æ•°æ®æ¸…æ´—

```python
# ========== ç¼ºå¤±å€¼å¤„ç† ==========
# æ£€æŸ¥ç¼ºå¤±å€¼
df.isna().sum()               # æ¯åˆ—ç¼ºå¤±æ•°
df.isna().any()               # å“ªäº›åˆ—æœ‰ç¼ºå¤±
df.dropna()                   # åˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ
df.dropna(subset=['age'])     # åªæ£€æŸ¥æŒ‡å®šåˆ—
df.dropna(how='all')          # å…¨ä¸ºç©ºæ‰åˆ é™¤
df.dropna(axis=1)             # åˆ é™¤å«ç¼ºå¤±å€¼çš„åˆ—

# å¡«å……ç¼ºå¤±å€¼
df.fillna(0)                          # å¡«å……å›ºå®šå€¼
df.fillna({'age': 0, 'city': 'æœªçŸ¥'})  # å„åˆ—ä¸åŒå€¼
df.fillna(df.mean())                  # å¡«å……å‡å€¼
df.fillna(method='ffill')             # å‰å‘å¡«å……
df.fillna(method='bfill')             # åå‘å¡«å……

# ========== é‡å¤å€¼å¤„ç† ==========
df.duplicated()               # æ£€æŸ¥é‡å¤ï¼ˆè¿”å›å¸ƒå°”ï¼‰
df.duplicated().sum()         # é‡å¤æ•°é‡
df.drop_duplicates()          # åˆ é™¤é‡å¤è¡Œ
df.drop_duplicates(subset=['name'])  # æŒ‰åˆ—å»é‡
df.drop_duplicates(keep='last')      # ä¿ç•™æœ€åä¸€ä¸ª

# ========== æ•°æ®ç±»å‹è½¬æ¢ ==========
df['age'] = df['age'].astype(int)
df['date'] = pd.to_datetime(df['date'])
df['price'] = pd.to_numeric(df['price'], errors='coerce')  # é”™è¯¯è½¬ NaN

# ========== å­—ç¬¦ä¸²å¤„ç† ==========
df['name'].str.lower()        # å°å†™
df['name'].str.upper()        # å¤§å†™
df['name'].str.strip()        # å»ç©ºæ ¼
df['name'].str.replace('å¼ ', 'ç‹')
df['name'].str.split(',')     # åˆ†å‰²
df['name'].str.len()          # é•¿åº¦
df['name'].str.startswith('å¼ ')
df['name'].str.contains('å¼ ')
```

#### 5. æ•°æ®ç»Ÿè®¡åˆ†æ

```python
# ========== åŸºç¡€ç»Ÿè®¡ ==========
df.describe()                  # æè¿°æ€§ç»Ÿè®¡
df.mean()                      # å‡å€¼
df.median()                    # ä¸­ä½æ•°
df.std()                       # æ ‡å‡†å·®
df.var()                       # æ–¹å·®
df.sum()                       # æ±‚å’Œ
df.count()                     # è®¡æ•°
df.max(), df.min()             # æœ€å¤§æœ€å°
df.quantile(0.25)              # åˆ†ä½æ•°

# ========== å•åˆ—ç»Ÿè®¡ ==========
df['age'].mean()
df['age'].value_counts()       # å€¼è®¡æ•°
df['city'].value_counts()      # åˆ†ç±»è®¡æ•°
df['city'].unique()            # å”¯ä¸€å€¼
df['city'].nunique()           # å”¯ä¸€å€¼æ•°é‡

# ========== ç›¸å…³æ€§ ==========
df.corr()                      # ç›¸å…³ç³»æ•°çŸ©é˜µ
df.cov()                       # åæ–¹å·®çŸ©é˜µ
```

---

### ğŸŸ  é‡è¦

#### 6. åˆ†ç»„èšåˆ (GroupBy)

```python
# ========== åŸºç¡€åˆ†ç»„ ==========
# å•åˆ—åˆ†ç»„
df.groupby('city')['age'].mean()
df.groupby('city')['age'].agg(['mean', 'max', 'min'])

# å¤šåˆ—åˆ†ç»„
df.groupby(['city', 'gender'])['age'].mean()

# å¤šåˆ—èšåˆ
df.groupby('city').agg({
    'age': ['mean', 'max'],
    'salary': ['sum', 'mean']
})

# ========== è‡ªå®šä¹‰èšåˆ ==========
df.groupby('city').agg({
    'age': lambda x: x.max() - x.min()
})

# ========== åˆ†ç»„åæ“ä½œ ==========
grouped = df.groupby('city')
grouped.get_group('åŒ—äº¬')      # è·å–æŸç»„
grouped.size()                 # å„ç»„å¤§å°
grouped.count()                # å„ç»„éç©ºè®¡æ•°

# ========== transform ==========
# è¿”å›ä¸åŸ DataFrame ç›¸åŒå½¢çŠ¶
df['avg_age'] = df.groupby('city')['age'].transform('mean')

# ========== apply ==========
# è‡ªå®šä¹‰å‡½æ•°
df.groupby('city').apply(lambda x: x.nlargest(3, 'age'))
```

#### 7. æ•°æ®åˆå¹¶

```python
# ========== concat æ‹¼æ¥ ==========
# ä¸Šä¸‹æ‹¼æ¥
pd.concat([df1, df2])
pd.concat([df1, df2], ignore_index=True)

# å·¦å³æ‹¼æ¥
pd.concat([df1, df2], axis=1)

# ========== merge è¿æ¥ ==========
# å†…è¿æ¥ï¼ˆé»˜è®¤ï¼‰
pd.merge(df1, df2, on='user_id')
pd.merge(df1, df2, on=['user_id', 'order_id'])

# å·¦è¿æ¥
pd.merge(df1, df2, on='user_id', how='left')

# å…¶ä»–è¿æ¥
pd.merge(df1, df2, on='user_id', how='right')  # å³è¿æ¥
pd.merge(df1, df2, on='user_id', how='outer')  # å¤–è¿æ¥

# ä¸åŒåˆ—å
pd.merge(df1, df2, left_on='id', right_on='user_id')

# ========== join ==========
df1.join(df2, on='key', lsuffix='_left', rsuffix='_right')

# ========== appendï¼ˆå·²å¼ƒç”¨ï¼Œç”¨ concatï¼‰==========
# pd.concat([df1, df2], ignore_index=True)
```

#### 8. æ•°æ®é€è§†è¡¨

```python
# ========== pivot_table ==========
# åŸºç¡€é€è§†è¡¨
pd.pivot_table(df, values='sales', index='city', columns='year', aggfunc='sum')

# å¤šå€¼å¤šèšåˆ
pd.pivot_table(df,
    values=['sales', 'profit'],
    index='city',
    columns='year',
    aggfunc={'sales': 'sum', 'profit': 'mean'}
)

# æ·»åŠ å°è®¡
pd.pivot_table(df, values='sales', index='city', columns='year',
               aggfunc='sum', margins=True)

# ========== crosstab äº¤å‰è¡¨ ==========
pd.crosstab(df['city'], df['gender'])
pd.crosstab(df['city'], df['gender'], margins=True)
pd.crosstab(df['city'], df['gender'], normalize='index')  # æŒ‰è¡Œå½’ä¸€åŒ–
```

#### 9. æ—¶é—´åºåˆ—å¤„ç†

```python
# ========== æ—¥æœŸè½¬æ¢ ==========
df['date'] = pd.to_datetime(df['date'])
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')

# ========== æå–æ—¥æœŸå±æ€§ ==========
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df['weekday'] = df['date'].dt.weekday          # 0=å‘¨ä¸€
df['hour'] = df['date'].dt.hour
df['quarter'] = df['date'].dt.quarter
df['is_weekend'] = df['date'].dt.weekday >= 5

# ========== æ—¥æœŸèŒƒå›´ ==========
pd.date_range('2024-01-01', '2024-12-31', freq='D')    # æ¯å¤©
pd.date_range('2024-01-01', periods=12, freq='M')      # 12 ä¸ªæœˆ
pd.date_range('2024-01-01', periods=10, freq='W')      # 10 å‘¨

# ========== é‡é‡‡æ · ==========
# æ—¶é—´åºåˆ—èšåˆ
df.resample('D', on='date').sum()        # æŒ‰å¤©
df.resample('W', on='date').mean()       # æŒ‰å‘¨
df.resample('M', on='date').sum()        # æŒ‰æœˆ

# ========== æ—¶é—´çª—å£ ==========
df.rolling(window=7).mean()              # 7 å¤©ç§»åŠ¨å¹³å‡
df.expanding().sum()                     # ç´¯è®¡æ±‚å’Œ
```

---

### ğŸŸ¡ å¸¸ç”¨

#### 10. æ•°æ®æ’åºä¸æ’å

```python
# ========== æ’åº ==========
df.sort_values('age')                    # æŒ‰å€¼æ’åº
df.sort_values('age', ascending=False)   # é™åº
df.sort_values(['city', 'age'])          # å¤šåˆ—æ’åº
df.sort_index()                          # æŒ‰ç´¢å¼•æ’åº

# ========== æ’å ==========
df['rank'] = df['score'].rank()          # æ’å
df['rank'] = df['score'].rank(ascending=False)
df['rank'] = df['score'].rank(method='dense')  # ç´§å‡‘æ’å

# nlargest / nsmallest
df.nlargest(10, 'score')                 # å‰ 10 å¤§
df.nsmallest(10, 'score')                # å‰ 10 å°
```

#### 11. æ•°æ®é‡å¡‘

```python
# ========== melt å®½å˜é•¿ ==========
df_melted = pd.melt(df, id_vars=['name'], value_vars=['math', 'english'])
df_melted = df.melt(id_vars=['name'], var_name='subject', value_name='score')

# ========== pivot é•¿å˜å®½ ==========
df_pivot = df.pivot(index='name', columns='subject', values='score')

# ========== stack / unstack ==========
df.stack()                               # åˆ—è½¬è¡Œ
df.unstack()                             # è¡Œè½¬åˆ—

# ========== transpose ==========
df.T                                     # è½¬ç½®
```

#### 12. æ•°æ®ä¿®æ”¹

```python
# ========== èµ‹å€¼ ==========
df['new_col'] = 0                        # æ–°åˆ—
df['new_col'] = df['col1'] + df['col2']
df.loc[0, 'name'] = 'æ–°åå­—'             # ä¿®æ”¹å•å…ƒæ ¼

# ========== apply ==========
df['name_upper'] = df['name'].apply(str.upper)
df['category'] = df['age'].apply(lambda x: 'é’å¹´' if x < 30 else 'ä¸­å¹´')

# ========== map ==========
df['gender_cn'] = df['gender'].map({'M': 'ç”·', 'F': 'å¥³'})

# ========== replace ==========
df['status'].replace({'active': 1, 'inactive': 0})

# ========== assign ==========
df = df.assign(
    total=df['col1'] + df['col2'],
    category='A'
)
```

---

### ğŸŸ¢ äº†è§£

#### 13. é«˜çº§ç‰¹æ€§

```python
# ========== å¤šå±‚ç´¢å¼• ==========
df = pd.DataFrame(np.random.randn(4, 2),
    index=[['A', 'A', 'B', 'B'], [1, 2, 1, 2]],
    columns=['X', 'Y'])
df.loc['A', 1]

# ========== æ ·å¼ ==========
df.style.highlight_max()
df.style.background_gradient()

# ========== ä¸ SQL äº¤äº’ ==========
import pandasql as ps
ps.sqldf("SELECT * FROM df WHERE age > 25")

# ========== æ€§èƒ½ä¼˜åŒ– ==========
# ä½¿ç”¨ dtype å‡å°‘å†…å­˜
df = pd.read_csv('data.csv', dtype={'id': 'int32', 'name': 'category'})

# åˆ†å—è¯»å–
for chunk in pd.read_csv('big.csv', chunksize=10000):
    process(chunk)
```

---

## ä¸‰ã€é¢è¯•é«˜é¢‘é—®é¢˜

### åŸºç¡€ç¯‡

| é—®é¢˜ | ç­”æ¡ˆ |
|------|------|
| Series å’Œ DataFrame åŒºåˆ«ï¼Ÿ | Series ä¸€ç»´ï¼ŒDataFrame äºŒç»´è¡¨æ ¼ |
| å¦‚ä½•è¯»å– CSVï¼Ÿ | `pd.read_csv('file.csv')` |
| å¦‚ä½•å¤„ç†ç¼ºå¤±å€¼ï¼Ÿ | `dropna()` åˆ é™¤ï¼Œ`fillna()` å¡«å…… |
| å¦‚ä½•å»é‡ï¼Ÿ | `drop_duplicates()` |
| iloc å’Œ loc åŒºåˆ«ï¼Ÿ | iloc ä½ç½®ç´¢å¼•ï¼Œloc æ ‡ç­¾ç´¢å¼• |

### è¿›é˜¶ç¯‡

| é—®é¢˜ | ç­”æ¡ˆ |
|------|------|
| groupby çš„å·¥ä½œæµç¨‹ï¼Ÿ | åˆ†å‰² â†’ åº”ç”¨ â†’ åˆå¹¶ |
| merge å’Œ join åŒºåˆ«ï¼Ÿ | merge æ›´çµæ´»ï¼Œjoin åŸºäºç´¢å¼• |
| å¦‚ä½•å®ç° SQL çš„ GROUP BYï¼Ÿ | `df.groupby().agg()` |
| å¦‚ä½•å¤„ç†å¤§æ•°æ®ï¼Ÿ | chunksize åˆ†å—ã€dtype ä¼˜åŒ– |
| mapã€applyã€applymap åŒºåˆ«ï¼Ÿ | map å…ƒç´ çº§ï¼Œapply è¡Œ/åˆ—çº§ï¼Œapplymap å…¨å…ƒç´  |

### é«˜çº§ç¯‡

| é—®é¢˜ | ç­”æ¡ˆ |
|------|------|
| å¦‚ä½•ä¼˜åŒ– Pandas æ€§èƒ½ï¼Ÿ | dtypeã€å‘é‡åŒ–ã€é¿å…å¾ªç¯ |
| å¦‚ä½•å¤„ç†æ—¶é—´åºåˆ—ï¼Ÿ | `to_datetime()`ã€`resample()` |
| pivot_table å’Œ pivot åŒºåˆ«ï¼Ÿ | pivot_table æ”¯æŒèšåˆ |

---

## å››ã€å®æˆ˜åœºæ™¯

### åœºæ™¯1ï¼šæµ‹è¯•æ•°æ®æ¯”å¯¹

```python
# æ¯”å¯¹ä¸¤ä¸ª Excel æ–‡ä»¶
df1 = pd.read_excel('expected.xlsx')
df2 = pd.read_excel('actual.xlsx')

# æ–¹å¼1ï¼šç›´æ¥æ¯”è¾ƒ
diff = df1.compare(df2)

# æ–¹å¼2ï¼šåˆå¹¶åæ‰¾å·®å¼‚
merged = pd.merge(df1, df2, how='outer', indicator=True)
diff = merged[merged['_merge'] != 'both']

# æ–¹å¼3ï¼šé€åˆ—æ¯”è¾ƒ
for col in df1.columns:
    if not df1[col].equals(df2[col]):
        print(f"åˆ— {col} ä¸ä¸€è‡´")
```

### åœºæ™¯2ï¼šç”Ÿæˆæµ‹è¯•æ•°æ®

```python
# ç”Ÿæˆéšæœºæµ‹è¯•æ•°æ®
import random

n = 1000
df = pd.DataFrame({
    'user_id': range(1, n + 1),
    'name': [f'ç”¨æˆ·{i}' for i in range(1, n + 1)],
    'age': np.random.randint(18, 60, n),
    'city': np.random.choice(['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³'], n),
    'amount': np.round(np.random.uniform(100, 10000, n), 2),
    'created_at': pd.date_range('2024-01-01', periods=n, freq='H')
})

df.to_csv('test_data.csv', index=False)
```

### åœºæ™¯3ï¼šæ•°æ®éªŒè¯

```python
# éªŒè¯æ•°æ®è´¨é‡
def validate_data(df):
    issues = []

    # æ£€æŸ¥ç©ºå€¼
    null_counts = df.isna().sum()
    for col, count in null_counts.items():
        if count > 0:
            issues.append(f"åˆ— {col} æœ‰ {count} ä¸ªç©ºå€¼")

    # æ£€æŸ¥é‡å¤
    dup_count = df.duplicated().sum()
    if dup_count > 0:
        issues.append(f"å‘ç° {dup_count} æ¡é‡å¤æ•°æ®")

    # æ£€æŸ¥å¼‚å¸¸å€¼
    if (df['age'] < 0).any():
        issues.append("å¹´é¾„å­˜åœ¨è´Ÿå€¼")

    return issues
```

### åœºæ™¯4ï¼šæ•°æ®ç»Ÿè®¡æŠ¥å‘Š

```python
# ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
def generate_report(df):
    report = {
        'æ€»è¡Œæ•°': len(df),
        'æ€»åˆ—æ•°': len(df.columns),
        'ç¼ºå¤±å€¼ç»Ÿè®¡': df.isna().sum().to_dict(),
        'æ•°å€¼åˆ—ç»Ÿè®¡': df.describe().to_dict(),
        'å”¯ä¸€å€¼ç»Ÿè®¡': {col: df[col].nunique() for col in df.columns}
    }
    return report
```

---

## äº”ã€Pandas é€ŸæŸ¥è¡¨

### æ•°æ®ç»“æ„

| æ“ä½œ | ä»£ç  |
|------|------|
| åˆ›å»º DataFrame | `pd.DataFrame(dict)` |
| æŸ¥çœ‹ | `df.head()`, `df.tail()`, `df.info()` |
| å½¢çŠ¶ | `df.shape` |
| åˆ—å | `df.columns` |

### é€‰æ‹©

| æ“ä½œ | ä»£ç  |
|------|------|
| é€‰åˆ— | `df['col']`, `df[['col1', 'col2']]` |
| é€‰è¡Œ | `df.iloc[i]`, `df.loc[i]` |
| æ¡ä»¶ | `df[df['col'] > value]` |

### æ¸…æ´—

| æ“ä½œ | ä»£ç  |
|------|------|
| åˆ é™¤ç©ºå€¼ | `df.dropna()` |
| å¡«å……ç©ºå€¼ | `df.fillna(value)` |
| å»é‡ | `df.drop_duplicates()` |
| ç±»å‹è½¬æ¢ | `df['col'].astype(type)` |

### ç»Ÿè®¡

| æ“ä½œ | ä»£ç  |
|------|------|
| æè¿°ç»Ÿè®¡ | `df.describe()` |
| å‡å€¼ | `df['col'].mean()` |
| è®¡æ•° | `df['col'].value_counts()` |
| åˆ†ç»„ | `df.groupby('col').agg()` |

### åˆå¹¶

| æ“ä½œ | ä»£ç  |
|------|------|
| æ‹¼æ¥ | `pd.concat([df1, df2])` |
| è¿æ¥ | `pd.merge(df1, df2, on='key')` |
| é€è§† | `pd.pivot_table()` |

---

## ç›¸å…³çŸ¥è¯†ç‚¹

- [[Python Requests ç²¾é€šæŒ‡å—]]
- [[SQL å‘½ä»¤æµ‹è¯•å·¥ç¨‹å¸ˆç²¾é€šæŒ‡å—]]
- [[Pytest é¢è¯•å®Œå…¨æŒ‡å—]]

---
*é‡‡é›†è‡ª Claude Code å¯¹è¯*

**Sources:**
- [Pandas å®˜æ–¹æ–‡æ¡£](https://pandas.pydata.org/)
- [30é“Pandasé«˜é¢‘è€ƒç‚¹å…¨è§£æ](https://blog.csdn.net/Rikki1013/article/details/150548297)
- [Pythonæ•°æ®åˆ†æé¢è¯•](https://www.fanruan.com/blog/article/1775901/)
